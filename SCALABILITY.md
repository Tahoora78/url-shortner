<div dir="ltr">

## 1. Handling Heavy Logging Workloads
<div dir="rtl">
فرض کنیم عملیات لاگ‌گیری برای هر ریکوئست بسیار سنگین است، مثلاً لازم است
در لحظه اطلاعات را به یک سرویس جانبی، یک پایگاه داده مجزا یا یک سیستم
آنالیتیکس ارسال کنیم. راه‌حل‌های پیشنهادی:

### الف) استفاده از معماری Asynchronous Logging

به‌جای ارسال مستقیم لاگ، آن را در یک **صف** قرار می‌دهیم و ارسال نهایی
توسط یک **Log Processor** جداگانه انجام می‌شود.\
ابزارهای مناسب:
- Kafka
- RabbitMQ
- Redis Streams

### ب) Batch Logging

-   ذخیره‌ی لاگ‌ها روی دیسک یا حافظه و ارسال آن‌ها به‌صورت **batch** پس از
    رسیدن به حجم مشخص.

### ج) File-based Logging 

-   نوشتن لاگ‌ها در فایل
-   ارسال فایل‌ها هر X دقیقه/ساعت به سرویس مرکزی.

------------------------------------------------------------------------

## 2. اگر سیستم روی چند سرور اجرا شود

### الف) Externalizing Dependencies

-    mysql --> Postgres
-   Cache → Redis
-   Queue → Kafka/RabbitMQ

### ب) انتخاب دیتابیس مناسب

-   چون روابط پیچیده بین جدول های دیتابیس نداریم میتونیم از MongoDB یا Cassandra استفاه کنیم
و اینکه این دیتابیس ها برای داده های زیاد scalability بهتری دارند.
-   برای analytics سنگین → ClickHouse

### ج) Distributed Locking

استفاده از **Redis distributed lock** برای جلوگیری از key collision.

### د) Network & Rate Control

-   Rate limit استفاده از 
-   API Gateway (Nginx) استفاده کردن از 

### هـ) Connection Pooling

هر instance باید pool جدا داشته باشد.

------------------------------------------------------------------------

##  فرض کن قراره یک کمپین تبلیغاتی اجرا بشه که ترافیک سنگینی به سرویس وارد میکنه. چه تصمیم هایی گرفتی که سرویس down نشه؟

### الف) Queueing عملیات سنگین

Increment-visit-count در queue قرار داده می‌شود تا race condition حذف
شود.

### ب) Pre-Generating Short Keys

کلیدها از قبل تولید و در دیتابیس ذخیره میشن و بعد به شکل batch روی cache قرار میگیرن.

### ج) Caching سنگین

استفاده از **LRU Cache** برای URLهای پرترافیک.

### د) Horizontal Scaling

اسکيل خودكار با Kubernetes.

### هـ) Rate Limiting & API Keys
برای جلوگیری از اینکه لود زیاد روی سرور ایجاد نشود.

### و) Resilience & Failure Handling

-   مانیتورینگ DB, Redis, Queue
-   شاردینگ دیتابیس
- چون تعداد ریکویست ها بالا هست از queue استفاده کردم برای قسمت increment-visit-count. به همین دلیل اگر از چند سرور هم استفاده کنیم به مشکل race condition نمیخوریم.
- برای تولید کردن short key از یک دیتابیس key استفاده کردم که به تعداد زیاد داخلش key تولید شده و از cache هم استفاده کردم. که فرایند تولید این کلید ها سریع باشه.
-  برای تعداد بالا میتونیم اول کل تعداد کلید ها را تولید کنیم بحای اینکه batch تا batch تا کلیدها رو تولید کنیم. که این کار فقط باید یک بار قبل از ران کردن سرویس انجام شود.(من الان این کار رو نکردم چون زمان زیادی برای تولید کردن همه ی key ها طول میکشید. کدش ساده هست ولی زمان اجرا زیاد هست)
-  برای url هایی که زیاد استفاده میشن از lru cache استفاده کردم تا کویری های دیتابیس کم بشود
- 
------------------------------------------------------------------------

## جمع‌بندی

1.  API سرورها باید **stateless** باشند.
2.  Logging و analytics باید async باشند.
3.  دیتابیس باید shared و scalable باشد.\
4.  Cache و Queue ضروری هستند.
5.  برای تایم هایی که حجم ریکویست ها بالا میرود باید autoscaling، rate limiting و caching پیاده شود.